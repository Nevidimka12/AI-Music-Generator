{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание и обучение модели LSTM на аккордах + длительностях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B79zndW6QtxB"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "# import fluidsynth\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Dict, List, Optional, Sequence, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задаем стандарный random seed и проверяем GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQu4uwsaQ285"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Sampling rate for audio playback\n",
    "_SAMPLING_RATE = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем csv данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LBcMwuMpQ426"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('TrainFiltChordino.csv').drop('Unnamed: 0', axis = 1)\n",
    "test = pd.read_csv('TestFiltChordino.csv').drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конвертируем csv в numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLlgPPTtSfBp"
   },
   "outputs": [],
   "source": [
    "trainData = []\n",
    "for i in train.index.values.tolist():\n",
    "    row = list(train.iloc[i])\n",
    "    trainData.append([[row[i], row[i+1]] for i in range(0,len(row),2)])\n",
    "testData = []\n",
    "for i in test.index.values.tolist():\n",
    "    row = list(test.iloc[i])\n",
    "    testData.append([[row[i], row[i+1]] for i in range(0,len(row),2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = np.array(testData)\n",
    "trainData = np.array(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zra2X_gLiDes"
   },
   "outputs": [],
   "source": [
    "trainData = np.array([item for sublist in trainData for item in sublist])\n",
    "testData = np.array([item for sublist in testData for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imcvUt7Ji5BH"
   },
   "outputs": [],
   "source": [
    "key_order = ['chord', 'duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем tf.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Ppcj3wTZxZQ",
    "outputId": "2bb4b8ad-57ed-402e-d98c-1620a0cf0a6c"
   },
   "outputs": [],
   "source": [
    "notes_ds = tf.data.Dataset.from_tensor_slices(trainData)\n",
    "notes_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vuJSWmuJdl6r"
   },
   "outputs": [],
   "source": [
    "def create_sequences(\n",
    "    dataset: tf.data.Dataset, \n",
    "    seq_length: int,\n",
    "    vocab_size = 128,\n",
    ") -> tf.data.Dataset:\n",
    "    seq_length = seq_length+1\n",
    "\n",
    "  # Take 1 extra for the labels\n",
    "    windows = dataset.window(seq_length, shift=1, stride=1,\n",
    "                              drop_remainder=True)\n",
    "    print(type(windows))\n",
    "  # `flat_map` flattens the\" dataset of datasets\" into a dataset of tensors\n",
    "    flatten = lambda x: x.batch(seq_length, drop_remainder=True)\n",
    "    sequences = windows.flat_map(flatten)\n",
    "\n",
    "  # Normalize note pitch\n",
    "    def scale_pitch(x):\n",
    "        x = x/[vocab_size,1.0]\n",
    "        return x\n",
    "\n",
    "  # Split the labels\n",
    "    def split_labels(sequences):\n",
    "        inputs = sequences[:-1]\n",
    "        labels_dense = sequences[-1]\n",
    "        labels = {key:labels_dense[i] for i,key in enumerate(key_order)}\n",
    "\n",
    "        return scale_pitch(inputs), labels\n",
    "\n",
    "    return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ORaDEFfHdl0O",
    "outputId": "fc8932bd-eb26-490d-8d24-fc6dce4bec4e"
   },
   "outputs": [],
   "source": [
    "seq_length = 50\n",
    "vocab_size = 200\n",
    "seq_ds = create_sequences(notes_ds, seq_length, vocab_size)\n",
    "seq_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка данных после преобразования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a1g5crvdlxP",
    "outputId": "434ab862-f64e-48f5-fc23-b111319c8feb"
   },
   "outputs": [],
   "source": [
    "for seq, target in seq_ds.take(1):\n",
    "    print('sequence shape:', seq.shape)\n",
    "    print('sequence elements (first 10):', seq[0: 10])\n",
    "    print()\n",
    "    print('target:', target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кешируем данные для более быстрого доступа, также перемешиваем и разделяем на batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpjwkun0dluw"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 10000 - seq_length  # the number of items in the dataset\n",
    "train_ds = (seq_ds\n",
    "            .shuffle(buffer_size)\n",
    "            .batch(batch_size, drop_remainder=True)\n",
    "            .cache()\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Написали свою функцию потерь, чтобы контролировать отрицательные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcVdAyiAdlrK"
   },
   "outputs": [],
   "source": [
    "def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
    "    mse = (y_true - y_pred) ** 2\n",
    "    positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n",
    "    return tf.reduce_mean(mse + positive_pressure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация модели и обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем модель загружаем функции ошибки, веса по параметрам и выводим данные о ней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-s7aCKlNdlmU",
    "outputId": "24408ffa-f607-4208-bcce-7c59d7457f7d"
   },
   "outputs": [],
   "source": [
    "input_shape = (seq_length, 2)\n",
    "learning_rate = 0.005\n",
    "\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "x = tf.keras.layers.LSTM(128)(inputs)\n",
    "\n",
    "outputs = {\n",
    "  'chord': tf.keras.layers.Dense(193, name='chord')(x),\n",
    "  'duration': tf.keras.layers.Dense(1, name='duration')(x),\n",
    "}\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "loss = {\n",
    "      'chord': tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "          from_logits=True),\n",
    "      'duration': mse_with_positive_pressure,\n",
    "}\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Elyc7rWUdlaT",
    "outputId": "16105a3e-d5ba-402b-9f4f-45bad8581c5e"
   },
   "outputs": [],
   "source": [
    "losses = model.evaluate(train_ds, return_dict=True)\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_g6k5GrkQkK"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=loss,\n",
    "    loss_weights={\n",
    "        'pitch': 0.5,\n",
    "        'duration':2.0,\n",
    "    },\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tu_iPxOzkRwz",
    "outputId": "eef769c0-c825-47f4-fbc9-82592249d2b8"
   },
   "outputs": [],
   "source": [
    "model.evaluate(train_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSX0zem8kRrF"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./training_checkpoints/ckpt_{epoch}',\n",
    "        save_weights_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dEDkXUockRop",
    "outputId": "9bee1f3d-7b74-40a8-b587-37c204930bc3"
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение графика ошибки по эпохам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "BhXsSmNckRlg",
    "outputId": "d89c1c53-e826-4e5e-f4e8-610284a58da3"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['loss'], label='total loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cозранение модели для будующего использования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"path/to/my_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
